{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlcirCastro/Trabalho-Final-IA/blob/main/TrabalhoFinal_LTNtorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install LTNtorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgHSjwjY0ZUk",
        "outputId": "cc7391f4-3b3b-4598-ef92-ac268ba678a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting LTNtorch\n",
            "  Downloading LTNtorch-1.0.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->LTNtorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->LTNtorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->LTNtorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->LTNtorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->LTNtorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->LTNtorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->LTNtorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, LTNtorch\n",
            "Successfully installed LTNtorch-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basededados1 = [[0.4, 0.12, 0.6, 0.9],[0.4, 0.12, 0.5, 0.9], [0.5, 0.2, 0.5, 0.7], [0.5, 0.2, 0.5, 0.6], [0.2, 0.2, 0.5, 0.6], [0.3, 0.2, 0.5, 0.6]]"
      ],
      "metadata": {
        "id": "1rSbadGu0cXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basededados2 = [[0.75, 0.20, 0.15, 0.5],[0.75, 0.20, 0.1, 0.4], [0.75, 0.25, 0.1, 0.4], [0.85, 0.25, 0.1, 0.1], [0.5, 0.25, 0.1, 0.1], [0.35, 0.25, 0.1, 0.1]]"
      ],
      "metadata": {
        "id": "7d1DwPsL9Ath"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = [1,1,1,1,1,0]"
      ],
      "metadata": {
        "id": "hFGl1ftE9VCN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import ltn\n",
        "\n",
        "class InSideRight(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InSideRight, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, A, B):\n",
        "        # Passa as características concatenadas pela rede neural\n",
        "        features = torch.cat((A,B), dim=1)\n",
        "\n",
        "        x = torch.relu(self.fc1(features))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Crie uma instância do predicado aprendido\n",
        "modelo_insideRight = InSideRight()\n",
        "\n",
        "# Defina a função de perda\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defina o otimizador\n",
        "optimizer1 = optim.Adam(modelo_insideRight.parameters(), lr=0.001)\n",
        "\n",
        "# Crie uma instância do dataset\n",
        "dataset1 = basededados1\n",
        "dataset2 = basededados2\n",
        "target = target  # Cast the target value to float\n",
        "\n",
        "# Loop de treinamento para o InSideRight\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0  # To keep track of the total loss for this epoch\n",
        "    optimizer1.zero_grad()\n",
        "\n",
        "    # Ajuste do loop para iterar sobre o dataset\n",
        "    for i in range(len(dataset1)):  # Assuming dataset contains both bbox and target values\n",
        "        # Converte o formato dos dados para adequar ao modelo\n",
        "        bbox1 = torch.tensor([dataset1[i]])  # x, y, w, h bb\n",
        "        bbox2 = torch.tensor([dataset2[i]])  # x, y, w, h bb\n",
        "        target_tensor = torch.tensor([target[i]], dtype=torch.float)  # Cast the target value to float\n",
        "\n",
        "        # Calcule a saída do predicado aprendido\n",
        "        output = modelo_insideRight(bbox1,bbox2)\n",
        "\n",
        "        # Calcule a perda\n",
        "        loss = loss_fn(output, target_tensor)  # Using Mean Squared Error loss\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Realize a retropropagação e atualize os pesos\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "    # Exiba a perda média a cada epoch, se desejado\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(dataset1)}')\n",
        "\n",
        "print(\"Training finished at Epoch %d with Avg Loss %.3f\" %(epoch, running_loss / len(dataset1)))\n",
        "\n",
        "print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2FBfDIS0fQK",
        "outputId": "bcd5a2c6-6d29-4216-8c5d-0b314b4536dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], Loss: 0.2979351704319318\n",
            "Epoch [100/1000], Loss: 0.12746477771239975\n",
            "Epoch [200/1000], Loss: 0.12523021541225413\n",
            "Epoch [300/1000], Loss: 0.11262306462352474\n",
            "Epoch [400/1000], Loss: 0.09650110028451309\n",
            "Epoch [500/1000], Loss: 0.08160658522198598\n",
            "Epoch [600/1000], Loss: 0.06934503858792596\n",
            "Epoch [700/1000], Loss: 0.05936868461139966\n",
            "Epoch [800/1000], Loss: 0.05092459961936887\n",
            "Epoch [900/1000], Loss: 0.04350620652136664\n",
            "Training finished at Epoch 999 with Avg Loss 0.037\n",
            "Training finished at Epoch 999 with Sat Level 0.838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basededados3 = [[0.3,0.2,0.5,0.6], [0.3,0.2,0.5,0.6], [0.5,0.2,0.5,0.6], [0.6, 0.2, 0.5, 0.5], [0.8, 0.2, 0.3, 0.5], [0.8,0.2, 0.3, 0.5]]"
      ],
      "metadata": {
        "id": "ZSa1EcYcB4Za"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basededados4 = [[0.35,0.25,0.1,0.1], [0.35,0.55,0.1,0.1], [0.55,0.5,0.1,0.1], [0.7, 0.5, 0.1, 0.1], [0.85, 0.5, 0.1, 0.1], [0.99,0.5, 0.1, 0.1]]"
      ],
      "metadata": {
        "id": "orQXuRS5CdMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target1 = [1,1,1,1,1,0]"
      ],
      "metadata": {
        "id": "ZwzSdTTTCvZN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import ltn\n",
        "\n",
        "class InSideLeft(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InSideLeft, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, A, B):\n",
        "        # Passa as características concatenadas pela rede neural\n",
        "        features = torch.cat((A,B), dim=1)\n",
        "\n",
        "        x = torch.relu(self.fc1(features))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Crie uma instância do predicado aprendido\n",
        "modelo_insideLeft = InSideLeft()\n",
        "\n",
        "# Defina a função de perda\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defina o otimizador\n",
        "optimizer2 = optim.Adam(modelo_insideLeft.parameters(), lr=0.001)\n",
        "\n",
        "# Crie uma instância do dataset\n",
        "dataset3 = basededados3\n",
        "dataset4 = basededados4\n",
        "target1 = target1  # Cast the target value to float\n",
        "\n",
        "# Loop de treinamento para o InSideRight\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0  # To keep track of the total loss for this epoch\n",
        "    optimizer2.zero_grad()\n",
        "\n",
        "    # Ajuste do loop para iterar sobre o dataset\n",
        "    for i in range(len(dataset3)):  # Assuming dataset contains both bbox and target values\n",
        "        # Converte o formato dos dados para adequar ao modelo\n",
        "        bbox1 = torch.tensor([dataset3[i]])  # x, y, w, h bb\n",
        "        bbox2 = torch.tensor([dataset4[i]])  # x, y, w, h bb\n",
        "        target_tensor = torch.tensor([target1[i]], dtype=torch.float)  # Cast the target value to float\n",
        "\n",
        "        # Calcule a saída do predicado aprendido\n",
        "        output = modelo_insideLeft(bbox1,bbox2)\n",
        "\n",
        "        # Calcule a perda\n",
        "        loss = loss_fn(output, target_tensor)  # Using Mean Squared Error loss\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Realize a retropropagação e atualize os pesos\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "    # Exiba a perda média a cada epoch, se desejado\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(dataset1)}')\n",
        "\n",
        "print(\"Training finished at Epoch %d with Avg Loss %.3f\" %(epoch, running_loss / len(dataset1)))\n",
        "\n",
        "print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHbvFJwwBPUg",
        "outputId": "a705fe6f-df18-4aa5-955e-239a4e746d2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], Loss: 0.21878747642040253\n",
            "Epoch [100/1000], Loss: 0.15195754768016437\n",
            "Epoch [200/1000], Loss: 0.15547946442772323\n",
            "Epoch [300/1000], Loss: 0.1544764994760044\n",
            "Epoch [400/1000], Loss: 0.15045274033521613\n",
            "Epoch [500/1000], Loss: 0.1430344881179432\n",
            "Epoch [600/1000], Loss: 0.1315367506661763\n",
            "Epoch [700/1000], Loss: 0.11571012833155692\n",
            "Epoch [800/1000], Loss: 0.09938779118238017\n",
            "Epoch [900/1000], Loss: 0.08939197145324822\n",
            "Training finished at Epoch 999 with Avg Loss 0.082\n",
            "Training finished at Epoch 999 with Sat Level 0.602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# URL da imagem no GitHub\n",
        "url = 'https://raw.githubusercontent.com/AlcirCastro/Trabalho-Final-IA/main/cachorro-adolescente.jpg'\n",
        "\n",
        "# Faça uma solicitação GET para a URL da imagem\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verifique se a solicitação foi bem-sucedida (código de status 200)\n",
        "if response.status_code == 200:\n",
        "    # Salve a imagem no disco\n",
        "    with open('cachorro-adolescente.jpg', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"Imagem salva com sucesso!\")\n",
        "else:\n",
        "    print(\"Erro ao baixar a imagem:\", response.status_code)\n",
        "\n",
        "# Carregamento do modelo YOLOv5\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "# Caminho da imagem\n",
        "image_path = \"/content/cachorro-adolescente.jpg\"\n",
        "\n",
        "# Carregar a imagem usando OpenCV\n",
        "image_cv2 = cv2.imread(image_path)\n",
        "\n",
        "# Obter as dimensões da imagem\n",
        "altura, largura, _ = image_cv2.shape\n",
        "\n",
        "\n",
        "# Realizar inferência na imagem\n",
        "results = model(image_cv2, size=640)\n",
        "dados = []\n",
        "# Acessar as coordenadas das bounding boxes, confiança e classe para cada detecção\n",
        "for detection in results.xyxy[0]:\n",
        "    x1, y1, x2, y2, confidence, class_id = detection.tolist()\n",
        "\n",
        "    # Normalizar as coordenadas\n",
        "    x1_normalizado = x1 / largura\n",
        "    y1_normalizado = y1 / altura\n",
        "    w_normalizado = (x2 - x1) / largura\n",
        "    h_normalizado = (y2 - y1) / altura\n",
        "\n",
        "    # Imprimir as coordenadas normalizadas das bounding boxes no terminal\n",
        "    print(f'Bounding Box Normalizada: (x1: {x1_normalizado:.2f}, y1: {y1_normalizado:.2f}, largura: {w_normalizado:.2f}, altura: {h_normalizado:.2f}), Confiança: {confidence:.2f}, ID da Classe: {class_id}')\n",
        "    bbx = [x1_normalizado,y1_normalizado,w_normalizado,h_normalizado]\n",
        "    dados.append(bbx)\n",
        "    # Desenhar a bounding box na imagem original\n",
        "    cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "    # Escrever o texto da classe e confiança\n",
        "    label = f'Classe: {int(class_id)}, Confiança: {confidence:.2f}'\n",
        "    cv2.putText(image_cv2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Salvar a imagem com as bounding boxes desenhadas\n",
        "output_image_path = 'imagem_com_bounding_boxes.jpg'\n",
        "cv2.imwrite(output_image_path, image_cv2)\n",
        "\n",
        "print(modelo_insideLeft(torch.tensor([dados[0]]),torch.tensor([dados[1]])))\n",
        "print(modelo_insideRight(torch.tensor([dados[0]]),torch.tensor([dados[1]])))"
      ],
      "metadata": {
        "id": "cjNGxNGoATvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f6d9060-fdbe-4e12-bca4-7da5281b6a05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2024-4-3 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem salva com sucesso!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bounding Box Normalizada: (x1: 0.13, y1: 0.03, largura: 0.39, altura: 0.93), Confiança: 0.88, ID da Classe: 0.0\n",
            "Bounding Box Normalizada: (x1: 0.45, y1: 0.35, largura: 0.27, altura: 0.65), Confiança: 0.73, ID da Classe: 16.0\n",
            "tensor([[0.99561]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.97209]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    }
  ]
}