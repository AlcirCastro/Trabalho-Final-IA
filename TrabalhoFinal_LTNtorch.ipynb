{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqba1s9bOj2QLOlvchfESg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlcirCastro/Trabalho-Final-IA/blob/main/TrabalhoFinal_LTNtorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install LTNtorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgHSjwjY0ZUk",
        "outputId": "2bd33b5f-2660-49f5-a97b-2cff0493e0f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: LTNtorch in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->LTNtorch) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->LTNtorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->LTNtorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basededados1 = [[0.4, 0.12, 0.6, 0.9],[0.4, 0.12, 0.5, 0.9], [0.5, 0.2, 0.5, 0.7], [0.5, 0.2, 0.5, 0.6], [0.2, 0.2, 0.5, 0.6], [0.3, 0.2, 0.5, 0.6]]"
      ],
      "metadata": {
        "id": "1rSbadGu0cXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basededados2 = [[0.75, 0.20, 0.15, 0.5],[0.75, 0.20, 0.1, 0.4], [0.75, 0.25, 0.1, 0.4], [0.85, 0.25, 0.1, 0.1], [0.5, 0.25, 0.1, 0.1], [0.35, 0.25, 0.1, 0.1]]"
      ],
      "metadata": {
        "id": "7d1DwPsL9Ath"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = [1,1,1,1,1,0]"
      ],
      "metadata": {
        "id": "hFGl1ftE9VCN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import ltn\n",
        "\n",
        "class InSideRight(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InSideRight, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, A, B):\n",
        "        # Passa as características concatenadas pela rede neural\n",
        "        features = torch.cat((A,B), dim=1)\n",
        "\n",
        "        x = torch.relu(self.fc1(features))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Crie uma instância do predicado aprendido\n",
        "modelo_insideRight = InSideRight()\n",
        "\n",
        "# Defina a função de perda\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defina o otimizador\n",
        "optimizer1 = optim.Adam(modelo_insideRight.parameters(), lr=0.001)\n",
        "\n",
        "# Crie uma instância do dataset\n",
        "dataset1 = basededados1\n",
        "dataset2 = basededados2\n",
        "target = target  # Cast the target value to float\n",
        "\n",
        "# Loop de treinamento para o InSideRight\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0  # To keep track of the total loss for this epoch\n",
        "    optimizer1.zero_grad()\n",
        "\n",
        "    # Ajuste do loop para iterar sobre o dataset\n",
        "    for i in range(len(dataset1)):  # Assuming dataset contains both bbox and target values\n",
        "        # Converte o formato dos dados para adequar ao modelo\n",
        "        bbox1 = torch.tensor([dataset1[i]])  # x, y, w, h bb\n",
        "        bbox2 = torch.tensor([dataset2[i]])  # x, y, w, h bb\n",
        "        target_tensor = torch.tensor([target[i]], dtype=torch.float)  # Cast the target value to float\n",
        "\n",
        "        # Calcule a saída do predicado aprendido\n",
        "        output = modelo_insideRight(bbox1,bbox2)\n",
        "\n",
        "        # Calcule a perda\n",
        "        loss = loss_fn(output, target_tensor)  # Using Mean Squared Error loss\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Realize a retropropagação e atualize os pesos\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "    # Exiba a perda média a cada epoch, se desejado\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(dataset1)}')\n",
        "\n",
        "print(\"Training finished at Epoch %d with Avg Loss %.3f\" %(epoch, running_loss / len(dataset1)))\n",
        "\n",
        "print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2FBfDIS0fQK",
        "outputId": "5fd02fc0-f8ea-45ea-a30e-52b2da9079e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], Loss: 0.21571378658215204\n",
            "Epoch [100/1000], Loss: 0.12933696014806628\n",
            "Epoch [200/1000], Loss: 0.13568299329684427\n",
            "Epoch [300/1000], Loss: 0.1365437216979141\n",
            "Epoch [400/1000], Loss: 0.13497332588303834\n",
            "Epoch [500/1000], Loss: 0.13210503613421073\n",
            "Epoch [600/1000], Loss: 0.12813197596309087\n",
            "Epoch [700/1000], Loss: 0.12297102308366448\n",
            "Epoch [800/1000], Loss: 0.11656026202642049\n",
            "Epoch [900/1000], Loss: 0.1089290864377593\n",
            "Training finished at Epoch 999 with Avg Loss 0.100\n",
            "Training finished at Epoch 999 with Sat Level 0.452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basededados3 = [[0.3,0.2,0.5,0.6], [0.3,0.2,0.5,0.6], [0.5,0.2,0.5,0.6], [0.6, 0.2, 0.5, 0.5], [0.8, 0.2, 0.3, 0.5], [0.8,0.2, 0.3, 0.5]]"
      ],
      "metadata": {
        "id": "ZSa1EcYcB4Za"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basededados4 = [[0.35,0.25,0.1,0.1], [0.35,0.55,0.1,0.1], [0.55,0.5,0.1,0.1], [0.7, 0.5, 0.1, 0.1], [0.85, 0.5, 0.1, 0.1], [0.99,0.5, 0.1, 0.1]]"
      ],
      "metadata": {
        "id": "orQXuRS5CdMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target1 = [1,1,1,1,1,0]"
      ],
      "metadata": {
        "id": "ZwzSdTTTCvZN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import ltn\n",
        "\n",
        "class InSideLeft(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InSideLeft, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, A, B):\n",
        "        # Passa as características concatenadas pela rede neural\n",
        "        features = torch.cat((A,B), dim=1)\n",
        "\n",
        "        x = torch.relu(self.fc1(features))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Crie uma instância do predicado aprendido\n",
        "modelo_insideLeft = InSideLeft()\n",
        "\n",
        "# Defina a função de perda\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defina o otimizador\n",
        "optimizer2 = optim.Adam(modelo_insideLeft.parameters(), lr=0.001)\n",
        "\n",
        "# Crie uma instância do dataset\n",
        "dataset3 = basededados3\n",
        "dataset4 = basededados4\n",
        "target1 = target1  # Cast the target value to float\n",
        "\n",
        "# Loop de treinamento para o InSideRight\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0  # To keep track of the total loss for this epoch\n",
        "    optimizer2.zero_grad()\n",
        "\n",
        "    # Ajuste do loop para iterar sobre o dataset\n",
        "    for i in range(len(dataset3)):  # Assuming dataset contains both bbox and target values\n",
        "        # Converte o formato dos dados para adequar ao modelo\n",
        "        bbox1 = torch.tensor([dataset3[i]])  # x, y, w, h bb\n",
        "        bbox2 = torch.tensor([dataset4[i]])  # x, y, w, h bb\n",
        "        target_tensor = torch.tensor([target1[i]], dtype=torch.float)  # Cast the target value to float\n",
        "\n",
        "        # Calcule a saída do predicado aprendido\n",
        "        output = modelo_insideLeft(bbox1,bbox2)\n",
        "\n",
        "        # Calcule a perda\n",
        "        loss = loss_fn(output, target_tensor)  # Using Mean Squared Error loss\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Realize a retropropagação e atualize os pesos\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "    # Exiba a perda média a cada epoch, se desejado\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(dataset1)}')\n",
        "\n",
        "print(\"Training finished at Epoch %d with Avg Loss %.3f\" %(epoch, running_loss / len(dataset1)))\n",
        "\n",
        "print(\"Training finished at Epoch %d with Sat Level %.3f\" %(epoch, 1 - loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHbvFJwwBPUg",
        "outputId": "790b3b67-1ed4-4880-eef1-03f081b0127c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/1000], Loss: 0.2613588248689969\n",
            "Epoch [100/1000], Loss: 0.15266930560270944\n",
            "Epoch [200/1000], Loss: 0.15705823510264358\n",
            "Epoch [300/1000], Loss: 0.15803028350152695\n",
            "Epoch [400/1000], Loss: 0.15725454045847678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "\n",
        "# Carregamento do modelo YOLOv5\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "path = input(\"Nome da foto: \")\n",
        "# Caminho da imagem\n",
        "image_path = path\n",
        "\n",
        "# Carregar a imagem usando OpenCV\n",
        "image_cv2 = cv2.imread(image_path)\n",
        "\n",
        "# Obter as dimensões da imagem\n",
        "altura, largura, _ = image_cv2.shape\n",
        "\n",
        "# Realizar inferência na imagem\n",
        "results = model(image_cv2, size=640)\n",
        "dados = []\n",
        "# Acessar as coordenadas das bounding boxes, confiança e classe para cada detecção\n",
        "for detection in results.xyxy[0]:\n",
        "    x1, y1, x2, y2, confidence, class_id = detection.tolist()\n",
        "\n",
        "    # Normalizar as coordenadas\n",
        "    x1_normalizado = x1 / largura\n",
        "    y1_normalizado = y1 / altura\n",
        "    w_normalizado = (x2 - x1) / largura\n",
        "    h_normalizado = (y2 - y1) / altura\n",
        "\n",
        "    # Imprimir as coordenadas normalizadas das bounding boxes no terminal\n",
        "    print(f'Bounding Box Normalizada: (x1: {x1_normalizado:.2f}, y1: {y1_normalizado:.2f}, largura: {w_normalizado:.2f}, altura: {h_normalizado:.2f}), Confiança: {confidence:.2f}, ID da Classe: {class_id}')\n",
        "    bbx = [x1_normalizado,y1_normalizado,w_normalizado,h_normalizado]\n",
        "    dados.append(bbx)\n",
        "    # Desenhar a bounding box na imagem original\n",
        "    cv2.rectangle(image_cv2, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "    # Escrever o texto da classe e confiança\n",
        "    label = f'Classe: {int(class_id)}, Confiança: {confidence:.2f}'\n",
        "    cv2.putText(image_cv2, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Salvar a imagem com as bounding boxes desenhadas\n",
        "output_image_path = 'imagem_com_bounding_boxes.jpg'\n",
        "cv2.imwrite(output_image_path, image_cv2)\n",
        "\n",
        "print(modelo_insideLeft(torch.tensor([dados[0]]),torch.tensor([dados[1]])))\n",
        "print(modelo_insideRight(torch.tensor([dados[0]]),torch.tensor([dados[1]])))"
      ],
      "metadata": {
        "id": "cjNGxNGoATvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}